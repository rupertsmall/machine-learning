<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Machine-learning by rupertsmall</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Machine-learning</h1>
      <h2 class="project-tagline">machine learning algorithms</h2>
      <a href="https://github.com/rupertsmall/machine-learning" class="btn">View on GitHub</a>
      <a href="https://github.com/rupertsmall/machine-learning/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/rupertsmall/machine-learning/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h3>
<a id="k-means-clustering" class="anchor" href="#k-means-clustering" aria-hidden="true"><span class="octicon octicon-link"></span></a>K-means clustering</h3>

<p>K-means clustering is one of many machine learning models which challenges a computer to discover some feature of the data "by itself". Here the feature is the property of belonging to a certain group or cluster. Data with 5 clusters may look something like this:</p>

<p><img src="https://cloud.githubusercontent.com/assets/7373621/8417723/38990686-1ea6-11e5-9398-a787e6e21f7f.jpg" alt="data clusters"></p>

<p>This is just randomly generated synthetic data, generated using <a href="https://github.com/rupertsmall/machine-learning/blob/master/K-means-clustering/create_k_cluster.m">create_k_cluster.m</a>. Although its simple to see using the human eye where the clusters are, the goal is to teach the computer how to identify any clusters that may be presented to it without the aid of a human being. To begin we need the computer to understand how to generate some guesses for where the clusters lie: how to algorithmically select a point from each cluster. One possibility is <a href="https://github.com/rupertsmall/machine-learning/blob/master/K-means-clustering/seed_k_means.m">seed_k_means.m</a> which places a rectangular grid over the data and keeps only those points on the grid which are close to the real cluster data. The data is randomly generated so the specific plots will look different for you, but may look something like this:</p>

<p><img src="https://cloud.githubusercontent.com/assets/7373621/8417724/38a2d58a-1ea6-11e5-88cc-8ade65a6171d.jpg" alt="clusters with seed guesses"></p>

<p>Here the big black dots are the computer's guesses for where the clusters are. We want the number of guesses to be slightly more than K to ensure the computer makes at least one correct guess for each cluster. As you can see there's alot of white space where the algorithm (rightly) doesn't make any guesses, because there are no real data points there.</p>

<p>The functions <a href="https://github.com/rupertsmall/machine-learning/blob/master/K-means-clustering/create_k_cluster.m">create_k_cluster.m</a> and <a href="https://github.com/rupertsmall/machine-learning/blob/master/K-means-clustering/seed_k_means.m">seed_k_means.m</a> are called as shown in <a href="https://github.com/rupertsmall/machine-learning/blob/master/K-means-clustering/k_means_plot.m">k_means_plot.m</a>. Notice in <a href="https://github.com/rupertsmall/machine-learning/blob/master/K-means-clustering/seed_k_means.m">seed_k_means.m</a> there are no <em>for</em> loops! Optimising the distance between guesses and the real cluster data is all done using matrix algebra which Matlab/Octave do extremely fast:</p>

<pre><code>[x_candidates y_candidates] = meshgrid(xmin:delta_x:xmax, ymin:delta_y:ymax);
x_candidates = reshape(x_candidates, NN+2*N+1,1);
y_candidates = reshape(y_candidates, NN+2*N+1,1);
xx = x_candidates.^2;
yy = y_candidates.^2;

xdot = kron(X./(XX + YY), x_candidates./(xx+yy));
ydot = kron(Y./(XX + YY), y_candidates./(xx+yy));
xdist = kron(exp(X),exp(-x_candidates)).^2;
ydist = kron(exp(Y),exp(-y_candidates)).^2;
dist = ((xdist+ydist)/2 - 1).^2;
dot = xdot + ydot -1;
dot = dot.^2;
measure = dist.*dot;
measure = reshape(measure, length(x_candidates), length(X));
[closest index] = min(measure);
</code></pre>

<p>Another example of using matrix operations instead of <em>for</em> loops can be seen in <a href="https://github.com/rupertsmall/distance-heat-maps/blob/master/get_min_perp.m">in this program</a> for calculating the minimum perpendicular distance between all points in a plane and a curve passing through the plane.</p>

<p>..work in progress</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/rupertsmall/machine-learning">Machine-learning</a> is maintained by <a href="https://github.com/rupertsmall">rupertsmall</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>

